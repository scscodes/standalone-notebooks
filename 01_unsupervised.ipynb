{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T10:38:21.679383Z",
     "start_time": "2024-12-12T10:36:35.438480Z"
    }
   },
   "source": [
    "# 01_unsupervised.ipynb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# Import utilities\n",
    "from setup_utils import (setup_db_connection, plr, save_intermediate_data,\n",
    "                            plot_histogram, plot_scatter, plot_line, plot_correlation_matrix)\n",
    "\n",
    "# Connect to DB and load data\n",
    "engine = setup_db_connection()\n",
    "vdf = pd.read_sql_query(\"\"\"select * from mimiciv.mimiciv_derived.vitalsign\"\"\", engine)\n",
    "\n",
    "# Preprocessing\n",
    "cols_vitals = ['heart_rate', 'resp_rate', 'mbp', 'temperature', 'spo2']\n",
    "cols_to_use_time = ['charttime','subject_id','heart_rate','resp_rate','mbp','temperature','spo2']\n",
    "\n",
    "df = vdf[cols_to_use_time].copy()\n",
    "df['charttime'] = pd.to_datetime(df['charttime'], errors='coerce')\n",
    "\n",
    "# Aggregate daily by subject\n",
    "df['charttime'] = df['charttime'].dt.date\n",
    "df = df.groupby(['subject_id', 'charttime'], as_index=False)[cols_vitals].mean()\n",
    "\n",
    "# Sample 5% of subjects for demonstration\n",
    "unique_subjects = df['subject_id'].unique()\n",
    "sample_size = int(len(unique_subjects)*0.05)\n",
    "np.random.seed(42)\n",
    "sampled_subjects = np.random.choice(unique_subjects, size=sample_size, replace=False)\n",
    "df = df[df['subject_id'].isin(sampled_subjects)]\n",
    "df = df.dropna()\n",
    "\n",
    "# IQR Outlier Removal\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[cols_vitals])\n",
    "\n",
    "# UMAP\n",
    "reducer = umap.UMAP(n_neighbors=50, min_dist=0.3, random_state=42, n_jobs=1)\n",
    "embedding = reducer.fit_transform(scaled_data)\n",
    "df['umap_x'] = embedding[:, 0]\n",
    "df['umap_y'] = embedding[:, 1]\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_data)\n",
    "df['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "distances = kmeans.transform(scaled_data)\n",
    "df['distance_to_center'] = [distances[i, lbl] for i, lbl in enumerate(kmeans_labels)]\n",
    "threshold = np.percentile(df['distance_to_center'], 95)\n",
    "df['kmeans_outlier'] = df['distance_to_center'] > threshold\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.50, min_samples=10)\n",
    "db_labels = dbscan.fit_predict(scaled_data)\n",
    "df['dbscan_label'] = db_labels\n",
    "df['dbscan_outlier'] = (db_labels == -1)\n",
    "\n",
    "# DBSCAN on UMAP\n",
    "dbscan_umap = DBSCAN(eps=0.50, min_samples=10)\n",
    "umap_labels = dbscan_umap.fit_predict(embedding)\n",
    "df['umap_dbscan_label'] = umap_labels\n",
    "df['umap_dbscan_outlier'] = (umap_labels == -1)\n",
    "\n",
    "def outlier_category(row):\n",
    "    km = row['kmeans_outlier']\n",
    "    db = row['dbscan_outlier']\n",
    "    ud = row['umap_dbscan_outlier']\n",
    "    outlier_methods = []\n",
    "    if km:\n",
    "        outlier_methods.append('KMeans')\n",
    "    if db:\n",
    "        outlier_methods.append('DBSCAN')\n",
    "    if ud:\n",
    "        outlier_methods.append('UMAP_DBSCAN')\n",
    "    if len(outlier_methods) == 0:\n",
    "        return 'No Outlier'\n",
    "    return ' & '.join(outlier_methods)\n",
    "\n",
    "df['outlier_combination'] = df.apply(outlier_category, axis=1)\n",
    "\n",
    "# Save intermediate data\n",
    "save_intermediate_data(df, 'data/intermediate_unsupervised.csv')\n",
    "plr()\n",
    "print(\"Unsupervised processing complete and data saved.\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@24/12/12 05:38:21\n",
      "Unsupervised processing complete and data saved.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91dd6c28fcbc93b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
